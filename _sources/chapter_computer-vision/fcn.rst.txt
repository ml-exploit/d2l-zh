
.. _sec_fcn:

全卷积网络
==========


如
:numref:`sec_semantic_segmentation`\ 中所介绍的那样，语义分割是对图像中的每个像素分类。
*全卷积网络*\ （fully convolutional
network，FCN）采用卷积神经网络实现了从图像像素到像素类别的变换
:cite:`Long.Shelhamer.Darrell.2015`\ 。
与我们之前在图像分类或目标检测部分介绍的卷积神经网络不同，全卷积网络将中间层特征图的高和宽变换回输入图像的尺寸：这是通过在
:numref:`sec_transposed_conv`\ 中引入的\ *转置卷积*\ （transposed
convolution）实现的。
因此，输出的类别预测与输入图像在像素级别上具有一一对应关系：通道维的输出即该位置对应像素的类别预测。

.. raw:: latex

   \diilbookstyleinputcell

.. code:: ipython3

    %matplotlib inline
    import albumentations as A
    import mlx.core as mx
    import mlx.nn as nn
    import mlx.nn.losses as losses
    import mlx.optimizers as optim
    import numpy as np
    from mlxim.model import create_model
    from d2l import mlx as d2l

构造模型
--------

下面我们了解一下全卷积网络模型最基本的设计。 如
:numref:`fig_fcn`\ 所示，全卷积网络先使用卷积神经网络抽取图像特征，然后通过\ :math:`1\times 1`\ 卷积层将通道数变换为类别个数，最后在
:numref:`sec_transposed_conv`\ 中通过转置卷积层将特征图的高和宽变换为输入图像的尺寸。
因此，模型输出与输入图像的高和宽相同，且最终输出通道包含了该空间位置像素的类别预测。

.. _fig_fcn:

.. figure:: ../img/fcn.svg

   全卷积网络


下面，我们使用在ImageNet数据集上预训练的ResNet-18模型来提取图像特征，并将该网络记为\ ``pretrained_net``\ 。
ResNet-18模型的最后几层包括全局平均汇聚层和全连接层，然而全卷积网络中不需要它们。

.. raw:: latex

   \diilbookstyleinputcell

.. code:: ipython3

    pretrained_net = create_model("resnet18", weights=True)
    [(key, value) for key, value in pretrained_net.children().items() if key in ["layer4", "avgpool", "fc"]]




.. raw:: latex

   \diilbookstyleoutputcell

.. parsed-literal::
    :class: output

    [('layer4',
      Sequential(
        (layers.0): BasicBlock(
          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=1, groups=1, bias=False)
          (bn1): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, groups=1, bias=False)
          (bn2): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (layers.0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), padding=(0, 0), dilation=1, groups=1, bias=False)
            (layers.1): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layers.1): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, groups=1, bias=False)
          (bn1): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=1, groups=1, bias=False)
          (bn2): BatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )),
     ('avgpool', AdaptiveAvgPool2d()),
     ('fc', Linear(input_dims=512, output_dims=1000, bias=True))]



接下来，我们创建一个全卷积网络\ ``net``\ 。
它复制了ResNet-18中大部分的预训练层，除了最后的全局平均汇聚层和最接近输出的全连接层。

.. raw:: latex

   \diilbookstyleinputcell

.. code:: ipython3

    pretrained_net_layers = [layer for name, layer in pretrained_net.children().items()]
    net = nn.Sequential(*pretrained_net_layers[:-2])

给定高度为320和宽度为480的输入，\ ``net``\ 的前向传播将输入的高和宽减小至原来的\ :math:`1/32`\ ，即10和15。

.. raw:: latex

   \diilbookstyleinputcell

.. code:: ipython3

    X = mx.random.normal(shape=[1, 320, 480, 3])
    net(X).shape




.. raw:: latex

   \diilbookstyleoutputcell

.. parsed-literal::
    :class: output

    (1, 10, 15, 512)



接下来使用\ :math:`1\times1`\ 卷积层将输出通道数转换为Pascal
VOC2012数据集的类数（21类）。
最后需要将特征图的高度和宽度增加32倍，从而将其变回输入图像的高和宽。
回想一下 :numref:`sec_padding`\ 中卷积层输出形状的计算方法：
由于\ :math:`(320-64+16\times2+32)/32=10`\ 且\ :math:`(480-64+16\times2+32)/32=15`\ ，我们构造一个步幅为\ :math:`32`\ 的转置卷积层，并将卷积核的高和宽设为\ :math:`64`\ ，填充为\ :math:`16`\ 。
我们可以看到如果步幅为\ :math:`s`\ ，填充为\ :math:`s/2`\ （假设\ :math:`s/2`\ 是整数）且卷积核的高和宽为\ :math:`2s`\ ，转置卷积核会将输入的高和宽分别放大\ :math:`s`\ 倍。

.. raw:: latex

   \diilbookstyleinputcell

.. code:: ipython3

    num_classes = 21
    net = nn.Sequential(
        *pretrained_net_layers[:-2],
        nn.Conv2d(512, num_classes, kernel_size=1),
        # nn.Upsample(scale_factor=32, mode='linear', align_corners=True) # 或 False
        nn.ConvTranspose2d(num_classes, num_classes, kernel_size=64, padding=16, stride=32)
    )

初始化转置卷积层
----------------

在图像处理中，我们有时需要将图像放大，即\ *上采样*\ （upsampling）。
*双线性插值*\ （bilinear interpolation）
是常用的上采样方法之一，它也经常用于初始化转置卷积层。

为了解释双线性插值，假设给定输入图像，我们想要计算上采样输出图像上的每个像素。

1. 将输出图像的坐标\ :math:`(x,y)`\ 映射到输入图像的坐标\ :math:`(x',y')`\ 上。
   例如，根据输入与输出的尺寸之比来映射。
   请注意，映射后的\ :math:`x′`\ 和\ :math:`y′`\ 是实数。
2. 在输入图像上找到离坐标\ :math:`(x',y')`\ 最近的4个像素。
3. 输出图像在坐标\ :math:`(x,y)`\ 上的像素依据输入图像上这4个像素及其与\ :math:`(x',y')`\ 的相对距离来计算。

双线性插值的上采样可以通过转置卷积层实现，内核由以下\ ``bilinear_kernel``\ 函数构造。
限于篇幅，我们只给出\ ``bilinear_kernel``\ 函数的实现，不讨论算法的原理。

.. raw:: latex

   \diilbookstyleinputcell

.. code:: ipython3

    def bilinear_kernel(in_channels, out_channels, kernel_size):
        factor = (kernel_size + 1) // 2
        if kernel_size % 2 == 1:
            center = factor - 1
        else:
            center = factor - 0.5
        og = (mx.arange(kernel_size).reshape(-1, 1),
              mx.arange(kernel_size).reshape(1, -1))
        filt = (1 - mx.abs(og[0] - center) / factor) * \
               (1 - mx.abs(og[1] - center) / factor)
        weight = np.zeros((in_channels, out_channels,
                              kernel_size, kernel_size))
        weight[range(in_channels), range(out_channels), :, :] = filt
        return mx.array(weight)

让我们用双线性插值的上采样实验它由转置卷积层实现。
我们构造一个将输入的高和宽放大2倍的转置卷积层，并将其卷积核用\ ``bilinear_kernel``\ 函数初始化。

.. raw:: latex

   \diilbookstyleinputcell

.. code:: ipython3

    # 创建转置卷积层并设置权重
    conv_trans = nn.ConvTranspose2d(3, 3, kernel_size=4, padding=1, stride=2,
                                     bias=False)
    # (3, 4, 4, 3) for mlx, (3,3,4,4) for pytorch
    conv_trans.weight = bilinear_kernel(3, 3, 4).transpose(1, 2, 3, 0)
    print(conv_trans.weight.shape)


.. raw:: latex

   \diilbookstyleoutputcell

.. parsed-literal::
    :class: output

    (3, 4, 4, 3)


读取图像\ ``X``\ ，将上采样的结果记作\ ``Y``\ 。为了打印图像，我们需要调整通道维的位置。

.. raw:: latex

   \diilbookstyleinputcell

.. code:: ipython3

    img = mx.array(np.asarray(d2l.Image.open('../img/catdog.jpg'))).astype(mx.float32) / 255# H W C
    X = mx.expand_dims(img, axis=0)
    Y = conv_trans(X)
    out_img = Y[0]
    print(mx.min(out_img), mx.max(out_img))


.. raw:: latex

   \diilbookstyleoutputcell

.. parsed-literal::
    :class: output

    array(0.00220588, dtype=float32) array(1, dtype=float32)


可以看到，转置卷积层将图像的高和宽分别放大了2倍。
除了坐标刻度不同，双线性插值放大的图像和在
:numref:`sec_bbox`\ 中打印出的原图看上去没什么两样。

.. raw:: latex

   \diilbookstyleinputcell

.. code:: ipython3

    d2l.set_figsize()
    print('input image shape:', img.shape)
    d2l.plt.imshow(img);
    print('output image shape:', out_img.shape)
    d2l.plt.imshow(out_img);


.. raw:: latex

   \diilbookstyleoutputcell

.. parsed-literal::
    :class: output

    input image shape: (561, 728, 3)
    output image shape: (1122, 1456, 3)



.. figure:: output_fcn_8421ff_17_1.svg


全卷积网络用双线性插值的上采样初始化转置卷积层。对于\ :math:`1\times 1`\ 卷积层，我们使用Xavier初始化参数。

.. raw:: latex

   \diilbookstyleinputcell

.. code:: ipython3

    # bilinear_kernel 函数返回的权重形状是 (in_channels, out_channels, kernel_size, kernel_size)
    W = bilinear_kernel(num_classes, num_classes, 64)
    mx.eval(net.parameters())
    # ConvTranspose2d 期望的权重形状是 (output_channels, kernel_H, kernel_W, input_channels)
    net.layers[-1].weight = W.transpose(1, 2, 3, 0)
    mx.eval(net.parameters())
    print(net.layers[-1].weight)


.. raw:: latex

   \diilbookstyleoutputcell

.. parsed-literal::
    :class: output

    array([[[[0.000244141, 0, 0, ..., 0, 0, 0],
             [0.000732422, 0, 0, ..., 0, 0, 0],
             [0.0012207, 0, 0, ..., 0, 0, 0],
             ...,
             [0.0012207, 0, 0, ..., 0, 0, 0],
             [0.000732422, 0, 0, ..., 0, 0, 0],
             [0.000244141, 0, 0, ..., 0, 0, 0]],
            [[0.000732422, 0, 0, ..., 0, 0, 0],
             [0.00219727, 0, 0, ..., 0, 0, 0],
             [0.00366211, 0, 0, ..., 0, 0, 0],
             ...,
             [0.00366211, 0, 0, ..., 0, 0, 0],
             [0.00219727, 0, 0, ..., 0, 0, 0],
             [0.000732422, 0, 0, ..., 0, 0, 0]],
            [[0.0012207, 0, 0, ..., 0, 0, 0],
             [0.00366211, 0, 0, ..., 0, 0, 0],
             [0.00610352, 0, 0, ..., 0, 0, 0],
             ...,
             [0.00610352, 0, 0, ..., 0, 0, 0],
             [0.00366211, 0, 0, ..., 0, 0, 0],
             [0.0012207, 0, 0, ..., 0, 0, 0]],
            ...,
            [[0.0012207, 0, 0, ..., 0, 0, 0],
             [0.00366211, 0, 0, ..., 0, 0, 0],
             [0.00610352, 0, 0, ..., 0, 0, 0],
             ...,
             [0.00610352, 0, 0, ..., 0, 0, 0],
             [0.00366211, 0, 0, ..., 0, 0, 0],
             [0.0012207, 0, 0, ..., 0, 0, 0]],
            [[0.000732422, 0, 0, ..., 0, 0, 0],
             [0.00219727, 0, 0, ..., 0, 0, 0],
             [0.00366211, 0, 0, ..., 0, 0, 0],
             ...,
             [0.00366211, 0, 0, ..., 0, 0, 0],
             [0.00219727, 0, 0, ..., 0, 0, 0],
             [0.000732422, 0, 0, ..., 0, 0, 0]],
            [[0.000244141, 0, 0, ..., 0, 0, 0],
             [0.000732422, 0, 0, ..., 0, 0, 0],
             [0.0012207, 0, 0, ..., 0, 0, 0],
             ...,
             [0.0012207, 0, 0, ..., 0, 0, 0],
             [0.000732422, 0, 0, ..., 0, 0, 0],
             [0.000244141, 0, 0, ..., 0, 0, 0]]],
           [[[0, 0.000244141, 0, ..., 0, 0, 0],
             [0, 0.000732422, 0, ..., 0, 0, 0],
             [0, 0.0012207, 0, ..., 0, 0, 0],
             ...,
             [0, 0.0012207, 0, ..., 0, 0, 0],
             [0, 0.000732422, 0, ..., 0, 0, 0],
             [0, 0.000244141, 0, ..., 0, 0, 0]],
            [[0, 0.000732422, 0, ..., 0, 0, 0],
             [0, 0.00219727, 0, ..., 0, 0, 0],
             [0, 0.00366211, 0, ..., 0, 0, 0],
             ...,
             [0, 0.00366211, 0, ..., 0, 0, 0],
             [0, 0.00219727, 0, ..., 0, 0, 0],
             [0, 0.000732422, 0, ..., 0, 0, 0]],
            [[0, 0.0012207, 0, ..., 0, 0, 0],
             [0, 0.00366211, 0, ..., 0, 0, 0],
             [0, 0.00610352, 0, ..., 0, 0, 0],
             ...,
             [0, 0.00610352, 0, ..., 0, 0, 0],
             [0, 0.00366211, 0, ..., 0, 0, 0],
             [0, 0.0012207, 0, ..., 0, 0, 0]],
            ...,
            [[0, 0.0012207, 0, ..., 0, 0, 0],
             [0, 0.00366211, 0, ..., 0, 0, 0],
             [0, 0.00610352, 0, ..., 0, 0, 0],
             ...,
             [0, 0.00610352, 0, ..., 0, 0, 0],
             [0, 0.00366211, 0, ..., 0, 0, 0],
             [0, 0.0012207, 0, ..., 0, 0, 0]],
            [[0, 0.000732422, 0, ..., 0, 0, 0],
             [0, 0.00219727, 0, ..., 0, 0, 0],
             [0, 0.00366211, 0, ..., 0, 0, 0],
             ...,
             [0, 0.00366211, 0, ..., 0, 0, 0],
             [0, 0.00219727, 0, ..., 0, 0, 0],
             [0, 0.000732422, 0, ..., 0, 0, 0]],
            [[0, 0.000244141, 0, ..., 0, 0, 0],
             [0, 0.000732422, 0, ..., 0, 0, 0],
             [0, 0.0012207, 0, ..., 0, 0, 0],
             ...,
             [0, 0.0012207, 0, ..., 0, 0, 0],
             [0, 0.000732422, 0, ..., 0, 0, 0],
             [0, 0.000244141, 0, ..., 0, 0, 0]]],
           [[[0, 0, 0.000244141, ..., 0, 0, 0],
             [0, 0, 0.000732422, ..., 0, 0, 0],
             [0, 0, 0.0012207, ..., 0, 0, 0],
             ...,
             [0, 0, 0.0012207, ..., 0, 0, 0],
             [0, 0, 0.000732422, ..., 0, 0, 0],
             [0, 0, 0.000244141, ..., 0, 0, 0]],
            [[0, 0, 0.000732422, ..., 0, 0, 0],
             [0, 0, 0.00219727, ..., 0, 0, 0],
             [0, 0, 0.00366211, ..., 0, 0, 0],
             ...,
             [0, 0, 0.00366211, ..., 0, 0, 0],
             [0, 0, 0.00219727, ..., 0, 0, 0],
             [0, 0, 0.000732422, ..., 0, 0, 0]],
            [[0, 0, 0.0012207, ..., 0, 0, 0],
             [0, 0, 0.00366211, ..., 0, 0, 0],
             [0, 0, 0.00610352, ..., 0, 0, 0],
             ...,
             [0, 0, 0.00610352, ..., 0, 0, 0],
             [0, 0, 0.00366211, ..., 0, 0, 0],
             [0, 0, 0.0012207, ..., 0, 0, 0]],
            ...,
            [[0, 0, 0.0012207, ..., 0, 0, 0],
             [0, 0, 0.00366211, ..., 0, 0, 0],
             [0, 0, 0.00610352, ..., 0, 0, 0],
             ...,
             [0, 0, 0.00610352, ..., 0, 0, 0],
             [0, 0, 0.00366211, ..., 0, 0, 0],
             [0, 0, 0.0012207, ..., 0, 0, 0]],
            [[0, 0, 0.000732422, ..., 0, 0, 0],
             [0, 0, 0.00219727, ..., 0, 0, 0],
             [0, 0, 0.00366211, ..., 0, 0, 0],
             ...,
             [0, 0, 0.00366211, ..., 0, 0, 0],
             [0, 0, 0.00219727, ..., 0, 0, 0],
             [0, 0, 0.000732422, ..., 0, 0, 0]],
            [[0, 0, 0.000244141, ..., 0, 0, 0],
             [0, 0, 0.000732422, ..., 0, 0, 0],
             [0, 0, 0.0012207, ..., 0, 0, 0],
             ...,
             [0, 0, 0.0012207, ..., 0, 0, 0],
             [0, 0, 0.000732422, ..., 0, 0, 0],
             [0, 0, 0.000244141, ..., 0, 0, 0]]],
           ...,
           [[[0, 0, 0, ..., 0.000244141, 0, 0],
             [0, 0, 0, ..., 0.000732422, 0, 0],
             [0, 0, 0, ..., 0.0012207, 0, 0],
             ...,
             [0, 0, 0, ..., 0.0012207, 0, 0],
             [0, 0, 0, ..., 0.000732422, 0, 0],
             [0, 0, 0, ..., 0.000244141, 0, 0]],
            [[0, 0, 0, ..., 0.000732422, 0, 0],
             [0, 0, 0, ..., 0.00219727, 0, 0],
             [0, 0, 0, ..., 0.00366211, 0, 0],
             ...,
             [0, 0, 0, ..., 0.00366211, 0, 0],
             [0, 0, 0, ..., 0.00219727, 0, 0],
             [0, 0, 0, ..., 0.000732422, 0, 0]],
            [[0, 0, 0, ..., 0.0012207, 0, 0],
             [0, 0, 0, ..., 0.00366211, 0, 0],
             [0, 0, 0, ..., 0.00610352, 0, 0],
             ...,
             [0, 0, 0, ..., 0.00610352, 0, 0],
             [0, 0, 0, ..., 0.00366211, 0, 0],
             [0, 0, 0, ..., 0.0012207, 0, 0]],
            ...,
            [[0, 0, 0, ..., 0.0012207, 0, 0],
             [0, 0, 0, ..., 0.00366211, 0, 0],
             [0, 0, 0, ..., 0.00610352, 0, 0],
             ...,
             [0, 0, 0, ..., 0.00610352, 0, 0],
             [0, 0, 0, ..., 0.00366211, 0, 0],
             [0, 0, 0, ..., 0.0012207, 0, 0]],
            [[0, 0, 0, ..., 0.000732422, 0, 0],
             [0, 0, 0, ..., 0.00219727, 0, 0],
             [0, 0, 0, ..., 0.00366211, 0, 0],
             ...,
             [0, 0, 0, ..., 0.00366211, 0, 0],
             [0, 0, 0, ..., 0.00219727, 0, 0],
             [0, 0, 0, ..., 0.000732422, 0, 0]],
            [[0, 0, 0, ..., 0.000244141, 0, 0],
             [0, 0, 0, ..., 0.000732422, 0, 0],
             [0, 0, 0, ..., 0.0012207, 0, 0],
             ...,
             [0, 0, 0, ..., 0.0012207, 0, 0],
             [0, 0, 0, ..., 0.000732422, 0, 0],
             [0, 0, 0, ..., 0.000244141, 0, 0]]],
           [[[0, 0, 0, ..., 0, 0.000244141, 0],
             [0, 0, 0, ..., 0, 0.000732422, 0],
             [0, 0, 0, ..., 0, 0.0012207, 0],
             ...,
             [0, 0, 0, ..., 0, 0.0012207, 0],
             [0, 0, 0, ..., 0, 0.000732422, 0],
             [0, 0, 0, ..., 0, 0.000244141, 0]],
            [[0, 0, 0, ..., 0, 0.000732422, 0],
             [0, 0, 0, ..., 0, 0.00219727, 0],
             [0, 0, 0, ..., 0, 0.00366211, 0],
             ...,
             [0, 0, 0, ..., 0, 0.00366211, 0],
             [0, 0, 0, ..., 0, 0.00219727, 0],
             [0, 0, 0, ..., 0, 0.000732422, 0]],
            [[0, 0, 0, ..., 0, 0.0012207, 0],
             [0, 0, 0, ..., 0, 0.00366211, 0],
             [0, 0, 0, ..., 0, 0.00610352, 0],
             ...,
             [0, 0, 0, ..., 0, 0.00610352, 0],
             [0, 0, 0, ..., 0, 0.00366211, 0],
             [0, 0, 0, ..., 0, 0.0012207, 0]],
            ...,
            [[0, 0, 0, ..., 0, 0.0012207, 0],
             [0, 0, 0, ..., 0, 0.00366211, 0],
             [0, 0, 0, ..., 0, 0.00610352, 0],
             ...,
             [0, 0, 0, ..., 0, 0.00610352, 0],
             [0, 0, 0, ..., 0, 0.00366211, 0],
             [0, 0, 0, ..., 0, 0.0012207, 0]],
            [[0, 0, 0, ..., 0, 0.000732422, 0],
             [0, 0, 0, ..., 0, 0.00219727, 0],
             [0, 0, 0, ..., 0, 0.00366211, 0],
             ...,
             [0, 0, 0, ..., 0, 0.00366211, 0],
             [0, 0, 0, ..., 0, 0.00219727, 0],
             [0, 0, 0, ..., 0, 0.000732422, 0]],
            [[0, 0, 0, ..., 0, 0.000244141, 0],
             [0, 0, 0, ..., 0, 0.000732422, 0],
             [0, 0, 0, ..., 0, 0.0012207, 0],
             ...,
             [0, 0, 0, ..., 0, 0.0012207, 0],
             [0, 0, 0, ..., 0, 0.000732422, 0],
             [0, 0, 0, ..., 0, 0.000244141, 0]]],
           [[[0, 0, 0, ..., 0, 0, 0.000244141],
             [0, 0, 0, ..., 0, 0, 0.000732422],
             [0, 0, 0, ..., 0, 0, 0.0012207],
             ...,
             [0, 0, 0, ..., 0, 0, 0.0012207],
             [0, 0, 0, ..., 0, 0, 0.000732422],
             [0, 0, 0, ..., 0, 0, 0.000244141]],
            [[0, 0, 0, ..., 0, 0, 0.000732422],
             [0, 0, 0, ..., 0, 0, 0.00219727],
             [0, 0, 0, ..., 0, 0, 0.00366211],
             ...,
             [0, 0, 0, ..., 0, 0, 0.00366211],
             [0, 0, 0, ..., 0, 0, 0.00219727],
             [0, 0, 0, ..., 0, 0, 0.000732422]],
            [[0, 0, 0, ..., 0, 0, 0.0012207],
             [0, 0, 0, ..., 0, 0, 0.00366211],
             [0, 0, 0, ..., 0, 0, 0.00610352],
             ...,
             [0, 0, 0, ..., 0, 0, 0.00610352],
             [0, 0, 0, ..., 0, 0, 0.00366211],
             [0, 0, 0, ..., 0, 0, 0.0012207]],
            ...,
            [[0, 0, 0, ..., 0, 0, 0.0012207],
             [0, 0, 0, ..., 0, 0, 0.00366211],
             [0, 0, 0, ..., 0, 0, 0.00610352],
             ...,
             [0, 0, 0, ..., 0, 0, 0.00610352],
             [0, 0, 0, ..., 0, 0, 0.00366211],
             [0, 0, 0, ..., 0, 0, 0.0012207]],
            [[0, 0, 0, ..., 0, 0, 0.000732422],
             [0, 0, 0, ..., 0, 0, 0.00219727],
             [0, 0, 0, ..., 0, 0, 0.00366211],
             ...,
             [0, 0, 0, ..., 0, 0, 0.00366211],
             [0, 0, 0, ..., 0, 0, 0.00219727],
             [0, 0, 0, ..., 0, 0, 0.000732422]],
            [[0, 0, 0, ..., 0, 0, 0.000244141],
             [0, 0, 0, ..., 0, 0, 0.000732422],
             [0, 0, 0, ..., 0, 0, 0.0012207],
             ...,
             [0, 0, 0, ..., 0, 0, 0.0012207],
             [0, 0, 0, ..., 0, 0, 0.000732422],
             [0, 0, 0, ..., 0, 0, 0.000244141]]]], dtype=float32)


读取数据集
----------

我们用
:numref:`sec_semantic_segmentation`\ 中介绍的语义分割读取数据集。
指定随机裁剪的输出图像的形状为\ :math:`320\times 480`\ ：高和宽都可以被\ :math:`32`\ 整除。

.. raw:: latex

   \diilbookstyleinputcell

.. code:: ipython3

    batch_size, crop_size = 4, (320, 480)
    train_iter, num_train_batches, test_iter, num_test_batches = d2l.load_data_voc(batch_size, crop_size)


.. raw:: latex

   \diilbookstyleoutputcell

.. parsed-literal::
    :class: output

    read 1114 examples
    read 1078 examples


训练
----

现在我们可以训练全卷积网络了。
这里的损失函数和准确率计算与图像分类中的并没有本质上的不同，因为我们使用转置卷积层的通道来预测像素的类别，所以需要在损失计算中指定通道维。
此外，模型基于每个像素的预测类别是否正确来计算准确率。

.. raw:: latex

   \diilbookstyleinputcell

.. code:: ipython3

    loss = losses.cross_entropy
    num_epochs, lr, wd = 5, 0.001, 1e-3
    trainer = optim.SGD(learning_rate=lr, weight_decay=wd)
    d2l.train_ch13(net, train_iter, num_train_batches, test_iter, loss, trainer, num_epochs)

预测
----

在预测时，我们需要将输入图像在各个通道做标准化，并转成卷积神经网络所需要的四维输入格式。

.. raw:: latex

   \diilbookstyleinputcell

.. code:: ipython3

    def predict(img):
        transform = A.Normalize(
                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        img = img.astype(np.float32) / 255
        X = mx.array(transform(image=img)["image"])
        X = mx.expand_dims(X, axis=0)
        print(X.shape)
        pred = net(X).argmax(axis=1)
        return pred.reshape(pred.shape[1], pred.shape[2])

为了可视化预测的类别给每个像素，我们将预测类别映射回它们在数据集中的标注颜色。

.. raw:: latex

   \diilbookstyleinputcell

.. code:: ipython3

    def label2image(pred):
        colormap = mx.array(d2l.VOC_COLORMAP)
        X = pred.astype(mx.int32)
        return colormap[X, :]

测试数据集中的图像大小和形状各异。
由于模型使用了步幅为32的转置卷积层，因此当输入图像的高或宽无法被32整除时，转置卷积层输出的高或宽会与输入图像的尺寸有偏差。
为了解决这个问题，我们可以在图像中截取多块高和宽为32的整数倍的矩形区域，并分别对这些区域中的像素做前向传播。
请注意，这些区域的并集需要完整覆盖输入图像。
当一个像素被多个区域所覆盖时，它在不同区域前向传播中转置卷积层输出的平均值可以作为\ ``softmax``\ 运算的输入，从而预测类别。

为简单起见，我们只读取几张较大的测试图像，并从图像的左上角开始截取形状为\ :math:`320\times480`\ 的区域用于预测。
对于这些测试图像，我们逐一打印它们截取的区域，再打印预测结果，最后打印标注的类别。

.. raw:: latex

   \diilbookstyleinputcell

.. code:: ipython3

    voc_dir = d2l.download_extract('voc2012', 'VOCdevkit/VOC2012')
    test_images, test_labels = d2l.read_voc_images(voc_dir, False)
    n, imgs = 4, []
    for i in range(n):
        # crop_rect = (0, 0, 320, 480)
        X, y = test_images[i], test_labels[i]
        transform = A.Crop(x_min=0, y_min=0, x_max=480, y_max=320)
        print(X.shape, y.shape)
        transformed = transform(image=X, mask=y)
        X = transformed['image']
        y = transformed['mask']
    
        pred = label2image(predict(X))
        imgs += [X, pred, y]
    d2l.show_images(imgs[::3] + imgs[1::3] + imgs[2::3], 3, n, scale=2);


.. raw:: latex

   \diilbookstyleoutputcell

.. parsed-literal::
    :class: output

    (366, 500, 3) (366, 500, 3)
    (1, 320, 480, 3)
    (335, 500, 3) (335, 500, 3)
    (1, 320, 480, 3)
    (333, 500, 3) (333, 500, 3)
    (1, 320, 480, 3)
    (375, 500, 3) (375, 500, 3)
    (1, 320, 480, 3)



.. figure:: output_fcn_8421ff_29_1.svg


小结
----

-  全卷积网络先使用卷积神经网络抽取图像特征，然后通过\ :math:`1\times 1`\ 卷积层将通道数变换为类别个数，最后通过转置卷积层将特征图的高和宽变换为输入图像的尺寸。
-  在全卷积网络中，我们可以将转置卷积层初始化为双线性插值的上采样。

练习
----

1. 如果将转置卷积层改用Xavier随机初始化，结果有什么变化？
2. 调节超参数，能进一步提升模型的精度吗？
3. 预测测试图像中所有像素的类别。
4. 最初的全卷积网络的论文中
   :cite:`Long.Shelhamer.Darrell.2015`\ 还使用了某些卷积神经网络中间层的输出。试着实现这个想法。
